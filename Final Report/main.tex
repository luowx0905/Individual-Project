\documentclass[12pt,twoside]{report}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Definitions for the title page
% Edit these to provide the correct information
% e.g. \newcommand{\reportauthor}{Timothy Kimber}

\newcommand{\reporttitle}{Analysing property sales data using Data Science}
\newcommand{\reportauthor}{Wenxiang Luo}
\newcommand{\supervisor}{Chiraag Lala}
\newcommand{\degreetype}{MSc Computing}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% load some definitions and default packages
\input{includes}

% load some macros
\input{notation}

\date{June 2022}

\begin{document}

% load title page
\input{titlepage}


% page numbering etc.
\pagenumbering{roman}
\clearpage{\pagestyle{empty}\cleardoublepage}
\setcounter{page}{1}
\pagestyle{plain}
\graphicspath{ {./figures/} }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
Your abstract.
\end{abstract}

\cleardoublepage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgments}
Comment this out if not needed.

\clearpage{\pagestyle{empty}\cleardoublepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%--- table of contents
\fancyhead[RE,LO]{\sffamily {Table of Contents}}
\tableofcontents 


\clearpage{\pagestyle{empty}\cleardoublepage}
\pagenumbering{arabic}
\setcounter{page}{1}
\fancyhead[LE,RO]{\slshape \rightmark}
\fancyhead[LO,RE]{\slshape \leftmark}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}

Nowadays, there is a substantial amount of data generated every second. The daily lives of humans are producing it, and some other fields, such as research, health care, economic activities, and environmental information from various sensors, also generate a vast amount of data. Obtaining the relationship between some features or the patterns underlying these massive amounts of data might benefit the entire world. For instance, new causes of diseases might be identified, and technological advancement could be accelerated.
\\

However, this extensive data can be one of the main obstacles for analysis as it is approximately impossible for humans to obtain insights into the data manually. Under this circumstance, artificial intelligence (AI), a technique that empowers the computer to imitate human intelligence and manner,  could be one of the methods to mitigate this issue. It can extract patterns from large datasets and use them to make predictions based on future data and even identify which data components are responsible for the results.
\\

In this project, some AI techniques will be applied to property and demographic data to gain insights and understand the factors influencing a homeowner's likelihood to sell. The factors might include the proximity to schools, hospitals, or supermarkets, the accessibility to public transportation, and the property types (flats or houses). It could be highly advantageous to estate agents who would discover homeowners with more potential to become clients and provide them with business. 

\section{Aim \& Objective}
\section{Layout of Thesis}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Literal Review}
Python is one of the most popular programming languages in the world since it is simple to develop, and there are extensive packages for various functionalities. In this project, Python and its packages would be used for loading data, preprocessing data, and constructing and evaluating machine learning models. 

\section{Machine Learning}
Machine Learning (ML), a subset of AI, is a technique that the computer can learn and improve from data without explicit programming. The reason for utilizing ML is that its performance is sometimes better than the conventional approach. For example, ML techniques would simplify the solution to a problem that comprises a long list of rules (spam mail detection). 
\\

ML can be divided into three categories, one of which is supervised learning. In supervised learning, the dataset contains features (input to the model) and targets (ground truth of the output), and the model's parameters are randomly initialized. Then the features are passed to the model, and the differences between the current output and the ground truth are used to update the parameters until the differences are acceptable. 
\\

In this project, a supervised learning model will be implemented for data analysis, and the steps are listed below.
\begin{enumerate}
	\item Data Preprocessing: Some data from the dataset may be missing, and these values must be handled appropriately before being passed to the model. 
	\item Standardization: In real life, different features usually have different ranges, and this will cause a problem in ML, which is that high magnitude features would have more weight than low magnitude features \citep{RN4}. One of the solutions is standardization, which could scale all the features to the same magnitude.
	\item Feature encoding: ML models require numerical values, whereas the categorical features in the dataset do not satisfy this requirement. Therefore, these features should be converted into numerical values. 
	\item Training \& Testing: The parameters of the model are updated, and it is expected that the loss will converge during training. The performance of the model is validated when testing.
\end{enumerate}

\section{Handle Text Information}
The format of texts in this project could be classified as HTML and plain text. Although Python standard libraries provide some string processing capabilities, they are insufficient for this situation. Therefore, \textit{\textbf{Beautiful Soup}} and \textit{\textbf{parse}}, two third-party packages, will be used to extract information from multiple texts.

\subsection{Beautiful Soup}
\textit{\textbf{Beautiful Soup}} is a Python library for extracting data from markup languages, such as HTML and XML. It can accomplish this with a user-specified parser, for example, \textbf{\textit{html.parser}}, to navigate, search and modify the parse tree, which would save considerable time \citep{RN10}. 
\\

In this project, this library will be used primarily to obtain a property's room information, including names and dimensions. In addition, other information in HTML format will be processed to acquire other features, such as council tax band and price. 

\subsection{parse}
The \textit{\textbf{format}} function in the Python standard library formats a string, whereas the \textit{\textbf{parse}} module provides functions with an oppositse effect, i.e., extract information. In this project, this module will be applied to acquire information such as numerical values from various strings.

\section{NumPy}
Numerical Python (\textit{\textbf{NumPy}}) is a scientific computing package utilizing an optimized C/C++ API to reduce computation time compared to pure Python computations \citep{RN6}. It provides some data structures, one of the most important structures is \textbf{\emph{ndarray}}. Unlike Python lists, NumPy arrays are homogenous, meaning all the elements in them are of the same type, and their sizes are constant \citep{RN4}.  In addition, NumPy provides various built-in functions for a variety of purposes, including statistics, linear algebra,  transforms, and element-wise operation. 
\\

In this project, \textit{\textbf{Numpy}} will be used for data preprocessing. For example, converting categorical data into integers.

\section{Pandas}
The \textbf{\textit{pandas}} is a fast and compelling package capable of handling data of various types (numerical values, strings, and time) and from multiple sources (CSV, Excel, and MqSQL database). One of the \textbf{\textit{pandas}} data structures is \textbf{\textit{DataFrame}} which is appropriate for handling tabular data with columns of different types. In addition, it could manage various operations, such as manipulating missing values, creating pivot tables (table summaries), and grouping data from different columns \citep{RN4}. 
\\

\textbf{\textit{Pandas}} would be used for data loading and preprocessing in this project. Data is initially loaded and represented as a \textbf{\textit{DataFrame}}. Then the attributes of the data, such as distribution, should be inspected. Finally, the data is preprocessed.

\section{Scikit-learn}
Scikit-learn is a Python ML package that provides various techniques for data mining, modeling, and analyzing. It could be commonly used in multiple ML tasks, such as classification, regression, and clustering. This project will use the package to analyze the performance of the models.

\section{PyTorch}
\textbf{\textit{PyTorch}} was developed by Facebook, and it is one of the popular libraries for constructing ML models. It is also the basis of numerous packages that the developers could take advantage of \citep{RN5}. In addition, this library is capable of performing auto differentiation by using graphic processing unit (GPU) acceleration, resulting in a reduction in training time. 
\\

In this project, some of the \textbf{\textit{PyTorch}} components will be utilized.
\begin{itemize}
	\item \textbf{\textit{nn.Sequential}} is the container that contains all the layers of the ML model
	\item An appropriate loss function would be selected to compute the loss and perform backpropagation. 
	\item One of the optimizers would be used to update the model's parameters. 
\end{itemize}

\section{Matplotlib}
\textbf{\textit{Matplotlib}} is one of the Python plotting packages for plotting different types of figures, including histograms, pie plots, and line plots. This library will be utilized primarily for data visualization in this project. For instance, the distribution of the raw data should be visualized to determine the procedures of preprocessing and plotting the training loss and validation loss during model evaluation. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Implementation}
\section{Data Preprocessing}
The data that was retrieved for this project originated from two different sources: a raw dataset and online APIs. 

\subsection{Extract Values}
There are two types of data in the raw dataset: HTML texts containing the property information and categorical keywords describing features, such as parking spaces and heating.

\subsubsection{Handle Room Descriptions (HTML)}
\textbf{\textit{\underline{Acquire room name and dimension}}} \\
The structure of the HTML texts containing the room information in a property is shown in figure \ref{html_structure}. The rooms are separated by tag \textit{$<$li$>$}, and the room name and its dimension is denoted by \textit{$<$strong$>$} and \textit{$<$i$>$} tags, respectively. Therefore, a function (\textit{\textbf{EweMove\_Description\_S3\_Rooms}}) was implemented to split the HTML text by utilizing \textit{\textbf{Beautiful soup}}, and its flowchart is shown in figure \ref{html_room_info}.
\begin{figure}[h]
	\centering
	\includegraphics[width=15cm]{html_structure}
	\caption{The layout of HTML texts}
	\label{html_structure}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=15cm]{html_room_info}
	\caption{Flowchart for extracting room information from HTML}
	\label{html_room_info}
\end{figure}

The names of rooms are analyzed after the room descriptions in the dataset have been processed. As a consequence, there are over 200 unique room names for approximately 3600 records, some of which are exceptionally uncommon across the entire dataset. For instance, only two properties have cinema rooms and one has a lift, which is less than 0.1\% of all entries.  
\\

Due to the large number of room names, it is impossible to use it as the input of the model. Therefore, the rooms are divided into seven categories: bedrooms, bathrooms, kitchens, living/reception rooms, dining rooms, work areas, and other rooms so that the data can be generalized. 
\\

\textbf{\textit{\underline{Generalize room information}}} \\
A class, \textit{\textbf{ExtractRooms}}, was developed to acquire and integrate the room information, especially the area in square meters, and its UML diagram is shown in figure \ref{uml_extract_rooms}. The member variable \textit{rooms} is a list containing the result of invoking \textit{EweMove\_Description\_S3\_Rooms}, \textit{room\_set} comprises all the room names, \textit{current\_rooms} consists of the room names that have been processed, and \textit{extract\_area} is a formatted string for acquiring room area. 
\\

\begin{figure}[h]
	\centering
	\includegraphics[width=10cm]{uml_extract_rooms}
	\caption{The UML diagram of the class (\textit{ExtractRooms})}
	\label{uml_extract_rooms}
\end{figure}

Key member functions
\begin{itemize}
	\item get\_rooms \\
	The flow diagram of this method is shown in figure \ref{extract_room_get_rooms} and the arguments are listed below.
	\begin{enumerate}
		\item args: It should be noted that this is a variable-length argument, which means that it can accept as many arguments as possible, and it is used to select room names from \textit{room\_set}. For instance, \textit{*args = ["living", "reception"]} will select all names containing "living" or "reception". 
		\item operation: The argumen determines the types of the final result and the valid inputs include \textit{"sum"}, \textit{"mean"}, \textit{"split"}, and \textit{"number"}. For example, if args is "bedroom", then the function can return the sum of bedroom areas, the average bedroom area, the area of each bedroom and the number of bedrooms. 
		\item handle\_na: This parameter specifies how to manage missing values, either by ignoring them or by filling the mean value if the input is "None" or "mean", respectively. 
	\end{enumerate} 
	\begin{figure}[h]
		\centering
		\includegraphics[height=10cm]{extract_room_get_rooms}
		\caption{Flowchart of \textit{get\_rooms}}
		\label{extract_room_get_rooms}
	\end{figure}
	\item get\_rest\_room: \\
	This method is identical to \textit{\textbf{get\_room}} with two exceptions. The parameter \textit{\textbf{*args}} is used to disgard the room names containing the keywords, and only the number and the total areas of other rooms are returned. 
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Testing the Implementation}
Comprehensive testing was conducted throughout the implementation but it is documented in this separate chapter for the sake of illuatration. 

\section{Data Preprocessing}

\subsection{Extract Values}

\subsubsection{Obtaining Room Information}
There were two tests for this objective, the first test examing if the room name and its dimension can be acquiare from HTML texts and the second test focuses on whether the room areas can be obtained and integrated correctly. 
\\

\textbf{\textit{\underline{Acquire room name and dimension}}} \\
Two HTML text snippets were utilized in this test and they are shonw in figure \ref{html_room_info_test}. By invoking function \textit{\textbf{EweMove\_Description\_S3\_Rooms}} with two snippets. It can be verified that all the room names and dimensions can be extracted without error and if the dimension is not available then it is set to one. 
\\
\begin{figure*}[h]
	\centering
	\subfigure[Snippte 1]{\includegraphics[width=7.5cm, height=8cm]{html_room_info_1}\label{html_room_info_test_1}}
	\hfill
	\subfigure[Snippet 2]{\includegraphics[width=7.5cm, height=8cm]{html_room_info_2}\label{html_room_info_test_2}}
	\caption{The HTML snippets for testing}
	\label{html_room_info_test}
\end{figure*}

\textbf{\textit{\underline{Generalize room information}}} \\
The information obtained from HTML texts (\ref{html_room_info_test}) were utilized to access the beahviour of \textit{ExtractRooms}, especially its member functions, \textit{get\_rooms}. During testing, the selected type is bedroom and all the operations of \textit{get\_room} were examed. In addition, the other rooms were applied to test \textit{get\_rest\_rooms}. 
\\

It is guaranteed that if the operation is  "split", then all the bedroom areas can be listed; the sum and average of areas, and the number of bedrooms will be returned if corresponding parameters are input to the function. Moreover, the number of other rooms and their total area will be computed correctly. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Experimental Results}

\section{Data Preprocessing}

\subsection{Extract Values}

\subsubsection{Obtaining Room Information}
\textbf{\textit{\underline{Acquire room name and dimension}}} \\
After calling the function and retrieving the results (shown in tables \ref{html_room_info_expect_1} and \ref{html_room_info_expect_2}), it is evident that the room names in two HTML snippets could be obtained, and the dimensions were acquired if available otherwise, the value was set to one, hence this function can pass the test.
\begin{table}[h]
	\centering
	\caption{Information from HTML snippet in figure \ref{html_room_info_test_1}}
	\begin{tabular} {| l | l |}
		\hline
		Entrance Hall & 1\\
		\hline
		Living/Dining Room & 6.58m x 3.78m (24.8 sqm) - 21' 7" x 12' 4" (267 sqft)\\
		\hline
		Kitchen & 2.68m x 2.14m (5.7 sqm) - 8' 9" x 7' (61 sqft)\\
		\hline
		Bedroom 1 & 3.37m x 2.45m (8.2 sqm) - 11' x 8' (88 sqft)\\
		\hline
		Bedroom 2 & 2.54m x 2.45m (6.2 sqm) - 8' 4" x 8' (67 sqft)\\
		\hline 
		Bathroom & 2.14m x 2.04m (4.3 sqm) - 7' x 6' 8" (46 sqft)\\
		\hline
		Garden & 1\\
		\hline
		Parking & 1\\
		\hline
	\end{tabular}
	\label{html_room_info_expect_1}
\end{table}

\begin{table}[h]
	\centering
	\caption{Information from HTML snippet in figure \ref*{html_room_info_test_2}}
	\begin{tabular} {| l | l |}
		\hline
		Entrance Porch & 1\\
		\hline
		Lounge Diner & 6.76m x 4.04m (27.3 sqm) - 22' 2" x 13' 3" (293 sqft)\\
		\hline
		Kitchen & 2.97m x 2.36m (7 sqm) - 9' 8" x 7' 8" (75 sqft)\\
		\hline
		Bathroom & 1\\
		\hline
		Bedroom (Double) & 4.05m x 3.25m (13.1 sqm) - 13' 3" x 10' 7" (142 sqft)\\
		\hline 
		Badroom (Double) & 3.28m x 2.36m (7.7 sqm) - 10' 9" x 7' 8" (83 sqft)\\
		\hline
		Bedroom (Double) & 4.3m x 2.44m (10.4 sqm) - 14' 1" x 8' (112 sqft)\\
		\hline
		Bathroom & 1\\
		\hline
	\end{tabular}
	\label{html_room_info_expect_2}
\end{table}

\textbf{\textit{\underline{Generalize room information}}} \\
The results of calling function \textit{get\_rooms} are shown in table \ref{bedroom_info_split} and \ref{bedroom_info_all}. It is obvious that all the bedrooms and their areas in table \ref{html_room_info_expect_1} and \ref{html_room_info_expect_2} were extracted successfully. In addition, if the operation was set to "mean", "sum" and "number", the numerical values could be obtained without error. These behaviours indicated that the functionalities are the same as the design. 
\\

Moreover, the result of invoking function \textit{get\_rest\_rooms} is shown in table \ref{other_room_info}. By applying the information from table \ref{bedroom_info_split}, \ref{html_room_info_expect_1} and \ref{html_room_info_expect_2}, it is clear that all the numerical values were matching which means this function can pass the test. 
\\ 

In summary, the manners of the two critical member functions in class \textit{ExtractRooms} meet the expections and the implementation is correct. 
\\

\begin{table}[h]
	\centering
	\captionof{table}{Room information ("split")}
	\label{bedroom_info_split}
	\begin{tabular}{| c | c | c | c |}
		\hline
		& Bedroom 1 & Bedroom 2 & Bedroom 3 \\
		\hline
		0 & 8.2 & 6.2 & 0.0 \\
		\hline
		1 & 13.1 & 7.7 & 10.4 \\
		\hline
	\end{tabular}
\end{table}

\begin{table*}[h]
	\centering
	\caption{Bedroom information integrated by different operations}
	\label{bedroom_info_all}
	\subtable[Mean]{
		\begin{tabular}{| c | c |}
			\hline
			& Average area \\ 
			\hline
			0 & 7.2 \\
			\hline
			1 & 10.4 \\ 
			\hline
		\end{tabular}
		\label{bedroom_info_mean}
	}
	\hfill
	\subtable[Sum]{
		\begin{tabular}{| c | c |}
			\hline
			& Total area \\ 
			\hline
			0 & 14.4 \\
			\hline
			1 & 31.2 \\ 
			\hline
		\end{tabular}
		\label{bedroom_info_sum}
	}
	\hfill
	\subtable[Number]{
		\begin{tabular}{| c | c |}
			\hline
			& Number of rooms \\ 
			\hline
			0 & 2 \\
			\hline
			1 & 3 \\ 
			\hline
		\end{tabular}
		\label{bedroom_info_number}
	}
\end{table*}

\begin{table}[h]
	\centering
	\caption{The number and total area of other rooms}
	\label{other_room_info}
	\begin{tabular}{| c | c | c |}
		\hline
		 & Number & Area \\
		 \hline
		 0 & 6 & 34.8 \\
		 \hline
		 1 & 5 & 34.3 \\
		 \hline
	\end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusion}


%% bibliography
\bibliographystyle{apalike}
\bibliography{proposal}

\end{document}
