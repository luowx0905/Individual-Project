{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Colab commands"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/Colab\\ Notebooks/build_model/TrainValidate.py /content\n",
    "!cp /content/drive/MyDrive/Colab\\ Notebooks/datasets/final_features_removed.csv /content\n",
    "!cp /content/drive/MyDrive/Colab\\ Notebooks/datasets/final_labels_removed.csv /content\n",
    "!cp /content/drive/MyDrive/Colab\\ Notebooks/datasets/final_sources_removed.csv /content\n",
    "!cp /content/drive/MyDrive/all_removed_weighted_sampler_full_epoch_1000_fold_2.pth /content\n",
    "!cp /content/drive/MyDrive/Colab\\ Notebooks/datasets/final_features_prices.csv /content\n",
    "!mkdir /content/models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install --quiet torchinfo\n",
    "!pip install --quiet torch_snippets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchinfo\n",
    "from torch_snippets import Report\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from TrainValidate import TrainValidate, create_weighted_sampler\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.has_mps:\n",
    "    device = \"mps\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"../datasets/final_features_removed.csv\")\n",
    "labels = pd.read_csv(\"../datasets/final_labels_removed.csv\")\n",
    "sources = pd.read_csv(\"../datasets/final_sources_removed.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create class for collecting data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class StatuePriceDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        assert len(features) == len(labels)\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        features = self.features.to_numpy()[item]\n",
    "        features = torch.tensor(features).float().to(device)\n",
    "\n",
    "        labels = self.labels.to_numpy()[item]\n",
    "        price = torch.tensor([labels[1]]).float().to(device)\n",
    "        status = torch.tensor([labels[0]]).float().to(device)\n",
    "\n",
    "        features = torch.cat([features, price])\n",
    "\n",
    "        return features, status\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp = StatuePriceDataset(features, labels)\n",
    "in_features = len(temp[0][0])\n",
    "in_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PredictPrice(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "\n",
    "        self.hidden = nn.Sequential(nn.Linear(in_features, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(128, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(128, 256),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(256, 128),\n",
    "                                    nn.ReLU())\n",
    "        self.price = nn.Sequential(nn.Linear(128, 1),\n",
    "                                   nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        price = self.price(x)\n",
    "        return price.squeeze()\n",
    "\n",
    "class PredictStatus(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(PredictStatus, self).__init__()\n",
    "\n",
    "        # Load model for predicting prices and freeze its parameters\n",
    "        filename = \"models/all_removed_weighted_sampler_full_epoch_1000_fold_2.pth\"\n",
    "        self.price = torch.load(filename, map_location=torch.device(\"cpu\"))\n",
    "        for param in self.price.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.hidden = nn.Sequential(nn.Linear(in_features+ 1, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(128, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(128, 256),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(256, 512),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(512, 256),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(256, 128),\n",
    "                                    nn.ReLU())\n",
    "        self.status = nn.Sequential(nn.Linear(128, 1),\n",
    "                                    nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        pred_price = self.price(x[:, :-1])[:, None]\n",
    "\n",
    "        new_features = torch.cat([x, pred_price], 1)\n",
    "        out = self.hidden(new_features)\n",
    "        out = self.status(out)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = PredictStatus(in_features)\n",
    "torchinfo.summary(model, input_size=(16, in_features))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')\n",
    "\n",
    "temp_data = StatuePriceDataset(features, labels)\n",
    "temp_loader = DataLoader(temp_data, batch_size=16)\n",
    "\n",
    "x, y = next(iter(temp_loader))\n",
    "x = x.to(\"cpu\")\n",
    "yhat = model(x)\n",
    "writer.add_graph(model, x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data standardization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "features[:] = scaler.transform(features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model\n",
    "## Prepare data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, random_state=1, test_size=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cross validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "torch.manual_seed(13)\n",
    "epochs = 1000\n",
    "\n",
    "for fold, (train_id, val_id) in enumerate(kfold.split(x_train.index)):\n",
    "    train_feature, train_label = x_train.iloc[train_id], y_train.iloc[train_id]\n",
    "    val_feature, val_label = x_train.iloc[val_id], y_train.iloc[val_id]\n",
    "    print(\"\\n\\n-------------This is fold {}----------------\".format(fold))\n",
    "\n",
    "    train_data = StatuePriceDataset(train_feature, train_label)\n",
    "    val_data = StatuePriceDataset(val_feature, val_label)\n",
    "    in_features = len(train_data[0][0])\n",
    "\n",
    "    train_sampler = create_weighted_sampler(train_feature[\"Sale or Let\"].values)\n",
    "    val_sampler = create_weighted_sampler(val_feature[\"Sale or Let\"].values)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=16, shuffle=False, drop_last=True, sampler=train_sampler)\n",
    "    val_loader = DataLoader(val_data, batch_size=16, shuffle=False, drop_last=True, sampler=val_sampler)\n",
    "\n",
    "    model = PredictStatus(in_features).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    train_validate = TrainValidate(model, nn.BCELoss(), optimizer)\n",
    "    train_validate.set_loader(train_loader, val_loader)\n",
    "    train_validate.train(epochs)\n",
    "\n",
    "    train_validate.save_model(\"models/status_removed_full_epoch_1000_fold_{}.pth\".format(fold))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filename = \"models/status_removed_full_epoch_1000_fold_4.pth\"\n",
    "\n",
    "model = torch.load(filename, map_location=torch.device(\"cpu\"))\n",
    "model.eval()\n",
    "completed, labels = [], []\n",
    "test_data = StatuePriceDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=16, shuffle=False, drop_last=False)\n",
    "\n",
    "for data in test_loader:\n",
    "    x, y = data\n",
    "    x = x.to(\"cpu\")\n",
    "    y = y.to(\"cpu\")\n",
    "\n",
    "    pred_com = model(x)\n",
    "    for item in pred_com.tolist():\n",
    "        completed.append(item[0])\n",
    "    for item in y.tolist():\n",
    "        labels.append(item[0])\n",
    "\n",
    "pred = pd.DataFrame({\"pred_completed\": completed, \"Truth\": labels})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"../datasets/final_labels.csv\")\n",
    "sale_rent = torch.tensor(labels[\"Completed\"].values)\n",
    "classes, count = sale_rent.unique(return_counts=True)\n",
    "classes, count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Add weighted sampler\n",
    "## Prepare data\n",
    "### Load datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"../datasets/final_features_removed.csv\")\n",
    "labels = pd.read_csv(\"../datasets/final_labels_removed.csv\")\n",
    "sources = pd.read_csv(\"../datasets/final_sources_removed.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data standardization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "features[:] = scaler.transform(features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, random_state=1, test_size=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cross validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "torch.manual_seed(13)\n",
    "epochs = 1000\n",
    "\n",
    "for fold, (train_id, val_id) in enumerate(kfold.split(x_train.index)):\n",
    "    train_feature, train_label = x_train.iloc[train_id], y_train.iloc[train_id]\n",
    "    val_feature, val_label = x_train.iloc[val_id], y_train.iloc[val_id]\n",
    "    print(\"\\n\\n-------------This is fold {}----------------\".format(fold))\n",
    "\n",
    "    train_data = StatuePriceDataset(train_feature, train_label)\n",
    "    val_data = StatuePriceDataset(val_feature, val_label)\n",
    "    in_features = len(train_data[0][0])\n",
    "\n",
    "    train_sampler = create_weighted_sampler(train_label[\"Completed\"].values)\n",
    "    val_sampler = create_weighted_sampler(val_label[\"Completed\"].values)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=16, shuffle=False, drop_last=True, sampler=train_sampler)\n",
    "    val_loader = DataLoader(val_data, batch_size=16, shuffle=False, drop_last=True, sampler=val_sampler)\n",
    "\n",
    "    model = PredictStatus(in_features).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "    train_validate = TrainValidate(model, nn.BCELoss(), optimizer)\n",
    "    train_validate.set_loader(train_loader, val_loader)\n",
    "    train_validate.train(epochs)\n",
    "\n",
    "    train_validate.save_model(\"models/status_ws_removed_full_epoch_1000_fold_{}.pth\".format(fold))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test performance (weighted sampler)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filename = \"models/status_ws_removed_full_epoch_1000_fold_3.pth\"\n",
    "\n",
    "model = torch.load(filename, map_location=torch.device(\"cpu\"))\n",
    "model.eval()\n",
    "completed, labels = [], []\n",
    "test_data = StatuePriceDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=16, shuffle=False, drop_last=False)\n",
    "\n",
    "for data in test_loader:\n",
    "    x, y = data\n",
    "    x = x.to(\"cpu\")\n",
    "    y = y.to(\"cpu\")\n",
    "\n",
    "    pred_com = model(x)\n",
    "    for item in pred_com.tolist():\n",
    "        completed.append(item[0])\n",
    "    for item in y.tolist():\n",
    "        labels.append(item[0])\n",
    "\n",
    "pred = pd.DataFrame({\"pred_completed\": completed, \"Truth\": labels})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load model without freezing parameters\n",
    "## Build model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PredictPrice(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "\n",
    "        self.hidden = nn.Sequential(nn.Linear(in_features, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(128, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(128, 256),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(256, 128),\n",
    "                                    nn.ReLU())\n",
    "        self.price = nn.Sequential(nn.Linear(128, 1),\n",
    "                                   nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        price = self.price(x)\n",
    "        return price.squeeze()\n",
    "\n",
    "class PredictStatus(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(PredictStatus, self).__init__()\n",
    "\n",
    "        # Load model for predicting prices and freeze its parameters\n",
    "        filename = \"models/all_removed_weighted_sampler_full_epoch_1000_fold_2.pth\"\n",
    "        self.price = torch.load(filename, map_location=torch.device(\"cpu\"))\n",
    "        for param in self.price.parameters():\n",
    "            pass\n",
    "            # param.requires_grad = False\n",
    "\n",
    "        self.hidden = nn.Sequential(nn.Linear(in_features+ 1, 256),\n",
    "                                    nn.Dropout(0.5),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(256, 512),\n",
    "                                    nn.Dropout(0.5),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(512, 1024),\n",
    "                                    nn.Dropout(0.5),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(1024, 256),\n",
    "                                    nn.Dropout(0.5),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(256, 64),\n",
    "                                    nn.Dropout(0.5),\n",
    "                                    nn.ReLU())\n",
    "        self.status = nn.Sequential(nn.Linear(64, 1),\n",
    "                                    nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        pred_price = self.price(x[:, :-1])[:, None]\n",
    "\n",
    "        new_features = torch.cat([x, pred_price], 1)\n",
    "        hidden = self.hidden(new_features)\n",
    "        out = self.status(hidden)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"../datasets/final_features_removed.csv\")\n",
    "labels = pd.read_csv(\"../datasets/final_labels_removed.csv\")\n",
    "sources = pd.read_csv(\"../datasets/final_sources_removed.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data standardization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "features[:] = scaler.transform(features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, random_state=1, test_size=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "torch.manual_seed(13)\n",
    "epochs = 1000\n",
    "\n",
    "for fold, (train_id, val_id) in enumerate(kfold.split(x_train.index)):\n",
    "    train_feature, train_label = x_train.iloc[train_id], y_train.iloc[train_id]\n",
    "    val_feature, val_label = x_train.iloc[val_id], y_train.iloc[val_id]\n",
    "    print(\"\\n\\n-------------This is fold {}----------------\".format(fold))\n",
    "\n",
    "    train_data = StatuePriceDataset(train_feature, train_label)\n",
    "    val_data = StatuePriceDataset(val_feature, val_label)\n",
    "    in_features = len(train_data[0][0])\n",
    "\n",
    "    train_sampler = create_weighted_sampler(train_label[\"Completed\"].values)\n",
    "    val_sampler = create_weighted_sampler(val_label[\"Completed\"].values)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=16, shuffle=False, drop_last=True, sampler=train_sampler)\n",
    "    val_loader = DataLoader(val_data, batch_size=16, shuffle=False, drop_last=True, sampler=val_sampler)\n",
    "\n",
    "    model = PredictStatus(in_features).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "    train_validate = TrainValidate(model, nn.BCELoss(), optimizer)\n",
    "    train_validate.set_loader(train_loader, val_loader)\n",
    "    train_validate.train(epochs)\n",
    "\n",
    "    train_validate.save_model(\"models/status_ws_removed_full_no_freeze_fold_{}.pth\".format(fold))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test performance (no freezing)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filename = \"models/status_ws_removed_full_no_freeze_fold_2.pth\"\n",
    "\n",
    "model = torch.load(filename, map_location=torch.device(\"cpu\"))\n",
    "model.eval()\n",
    "completed, labels = [], []\n",
    "test_data = StatuePriceDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=16, shuffle=False, drop_last=False)\n",
    "\n",
    "for data in test_loader:\n",
    "    x, y = data\n",
    "    x = x.to(\"cpu\")\n",
    "    y = y.to(\"cpu\")\n",
    "\n",
    "    pred_com = model(x)\n",
    "    for item in pred_com.tolist():\n",
    "        completed.append(item[0])\n",
    "    for item in y.tolist():\n",
    "        labels.append(item[0])\n",
    "\n",
    "pred = pd.DataFrame({\"pred_completed\": completed, \"Truth\": labels})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predict status (append predicted prices)\n",
    "## Load model for predicting prices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PredictPrice(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "\n",
    "        self.hidden = nn.Sequential(nn.Linear(in_features, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(128, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(128, 256),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(256, 128),\n",
    "                                    nn.ReLU())\n",
    "        self.price = nn.Sequential(nn.Linear(128, 1),\n",
    "                                   nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        price = self.price(x)\n",
    "        return price.squeeze()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"../datasets/final_features_removed.csv\")\n",
    "labels = pd.read_csv(\"../datasets/final_labels_removed.csv\")\n",
    "sources = pd.read_csv(\"../datasets/final_sources_removed.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data standardization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "features[:] = scaler.transform(features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predict prices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filename = \"models/all_removed_weighted_sampler_full_epoch_1000_fold_2.pth\"\n",
    "model = torch.load(filename, map_location=torch.device(\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "prices = []\n",
    "for i in range(len(features)):\n",
    "    feature = torch.tensor((features.iloc[i])).float()\n",
    "    pred_price = model(feature)\n",
    "    prices.append(pred_price.detach().item())\n",
    "\n",
    "pred = pd.DataFrame({\"PredictPrice\": prices, \"Price\": labels[\"Price / Rent\"]})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merge prices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"../datasets/final_features_removed.csv\")\n",
    "labels = pd.read_csv(\"../datasets/final_labels_removed.csv\")\n",
    "sources = pd.read_csv(\"../datasets/final_sources_removed.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features[\"Predict Price\"] = pred[\"PredictPrice\"]\n",
    "features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PredictStatus(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(PredictStatus, self).__init__()\n",
    "\n",
    "        self.hidden = nn.Sequential(nn.Linear(in_features, 256),\n",
    "                                    nn.BatchNorm1d(256),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(256, 512),\n",
    "                                    nn.BatchNorm1d(512),\n",
    "                                    nn.Dropout(0.5),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(512, 1024),\n",
    "                                    nn.BatchNorm1d(1024),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(1024, 256),\n",
    "                                    nn.BatchNorm1d(256),\n",
    "                                    nn.Dropout(0.5),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(256, 64),\n",
    "                                    nn.BatchNorm1d(64),\n",
    "                                    nn.Dropout(0.5),\n",
    "                                    nn.ReLU())\n",
    "        self.status = nn.Sequential(nn.Linear(64, 1),\n",
    "                                    nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.hidden(x)\n",
    "        out = self.status(hidden)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp = StatuePriceDataset(features, labels)\n",
    "in_features = len(temp[0][0])\n",
    "in_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data standardization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "features[:] = scaler.transform(features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, random_state=1, test_size=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "torch.manual_seed(13)\n",
    "epochs = 1000\n",
    "\n",
    "for fold, (train_id, val_id) in enumerate(kfold.split(x_train.index)):\n",
    "    train_feature, train_label = x_train.iloc[train_id], y_train.iloc[train_id]\n",
    "    val_feature, val_label = x_train.iloc[val_id], y_train.iloc[val_id]\n",
    "    print(\"\\n\\n-------------This is fold {}----------------\".format(fold))\n",
    "\n",
    "    train_data = StatuePriceDataset(train_feature, train_label)\n",
    "    val_data = StatuePriceDataset(val_feature, val_label)\n",
    "    in_features = len(train_data[0][0])\n",
    "\n",
    "    train_sampler = create_weighted_sampler(train_label[\"Completed\"].values)\n",
    "    val_sampler = create_weighted_sampler(val_label[\"Completed\"].values)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=16, shuffle=False, drop_last=True, sampler=train_sampler)\n",
    "    val_loader = DataLoader(val_data, batch_size=16, shuffle=False, drop_last=True, sampler=val_sampler)\n",
    "\n",
    "    model = PredictStatus(in_features).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    train_validate = TrainValidate(model, nn.BCELoss(), optimizer)\n",
    "    train_validate.set_loader(train_loader, val_loader)\n",
    "    train_validate.train(epochs)\n",
    "\n",
    "    train_validate.save_model(\"models/status_append_ws_removed_full_no_freeze_fold_{}.pth\".format(fold))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test performance (append predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filename = \"models/status_append_ws_removed_full_no_freeze_fold_2.pth\"\n",
    "\n",
    "model = torch.load(filename, map_location=torch.device(\"cpu\"))\n",
    "model.eval()\n",
    "completed, labels = [], []\n",
    "test_data = StatuePriceDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=16, shuffle=False, drop_last=False)\n",
    "\n",
    "for data in test_loader:\n",
    "    x, y = data\n",
    "    x = x.to(\"cpu\")\n",
    "    y = y.to(\"cpu\")\n",
    "\n",
    "    pred_com = model(x)\n",
    "    pred_com = torch.where(pred_com > 0.5, 1.0, 0.0)\n",
    "    for item in pred_com.tolist():\n",
    "        completed.append(item[0])\n",
    "    for item in y.tolist():\n",
    "        labels.append(item[0])\n",
    "\n",
    "pred = pd.DataFrame({\"pred_completed\": completed, \"Truth\": labels})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classes, count = np.unique(labels[\"Completed\"].values, return_counts=True)\n",
    "classes, count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cm = confusion_matrix(pred[\"pred_completed\"], pred[\"Truth\"])\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g')\n",
    "plt.xlabel(\"Prediction\")\n",
    "plt.ylabel(\"Truth\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "ax.xaxis.set_ticklabels(['Completed', 'Not Completed'])\n",
    "ax.yaxis.set_ticklabels(['Completed', 'Not Completed'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}