{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Colab commands"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/Colab\\ Notebooks/build_model/TrainValidate.py /content\n",
    "!cp /content/drive/MyDrive/Colab\\ Notebooks/datasets/final_features_removed.csv /content\n",
    "!cp /content/drive/MyDrive/Colab\\ Notebooks/datasets/final_labels_removed.csv /content\n",
    "!cp /content/drive/MyDrive/Colab\\ Notebooks/datasets/final_sources_removed.csv /content\n",
    "!cp /content/drive/MyDrive/all_removed_weighted_sampler_full_epoch_1000_fold_2.pth /content\n",
    "!mkdir /content/models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install --quiet torchinfo\n",
    "!pip install --quiet torch_snippets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchinfo\n",
    "from torch_snippets import Report\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from TrainValidate import TrainValidate, create_weighted_sampler\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.has_mps:\n",
    "    device = \"mps\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'mps'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"../datasets/final_features_removed.csv\")\n",
    "labels = pd.read_csv(\"../datasets/final_labels_removed.csv\")\n",
    "sources = pd.read_csv(\"../datasets/final_sources_removed.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create class for collecting data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class PriceDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        assert len(features) == len(labels)\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        features = self.features.to_numpy()[item]\n",
    "        features = torch.tensor(features).float().to(device)\n",
    "\n",
    "        labels = self.labels.to_numpy()[item]\n",
    "        price = torch.tensor(labels[1]).float().to(device)\n",
    "\n",
    "        return features, price\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "temp = PriceDataset(features, labels)\n",
    "in_features = len(temp[0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class PredictPrice(nn.Module):\n",
    "    def __init__(self, in_features, num_layers, num_neurons, activation):\n",
    "        super(PredictPrice, self).__init__()\n",
    "        self.hidden = nn.Sequential()\n",
    "\n",
    "        activation = activation.lower()\n",
    "        activation_fn = None\n",
    "        if activation == \"relu\":\n",
    "            activation_fn = nn.ReLU()\n",
    "        elif activation == \"sigmoid\":\n",
    "            activation_fn = nn.Sigmoid()\n",
    "        elif activation == \"tanh\":\n",
    "            activation_fn = nn.Tanh()\n",
    "\n",
    "        self.hidden.add_module(\"input\", nn.Linear(in_features, num_neurons))\n",
    "        for num in range(num_layers):\n",
    "            self.hidden.add_module(\"linear{}\".format(num), nn.Linear(num_neurons, num_neurons))\n",
    "            self.hidden.add_module(\"activation\", activation_fn)\n",
    "\n",
    "        self.price = nn.Sequential(nn.Linear(num_neurons, 1),\n",
    "                                   activation_fn)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.hidden(x)\n",
    "        out = self.price(out)\n",
    "        return out.squeeze()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nPredictPrice                             --                        --\n├─Sequential: 1-1                        [1, 256]                  --\n│    └─Linear: 2-1                       [1, 256]                  13,312\n│    └─Linear: 2-2                       [1, 256]                  65,792\n├─Sequential: 1                          --                        --\n│    └─Sigmoid: 2-3                      [1, 256]                  --\n├─Sequential: 1                          --                        --\n│    └─Linear: 2-4                       [1, 256]                  65,792\n│    └─Linear: 2-5                       [1, 256]                  65,792\n│    └─Linear: 2-6                       [1, 256]                  65,792\n│    └─Linear: 2-7                       [1, 256]                  65,792\n│    └─Linear: 2-8                       [1, 256]                  65,792\n│    └─Linear: 2-9                       [1, 256]                  65,792\n│    └─Linear: 2-10                      [1, 256]                  65,792\n│    └─Linear: 2-11                      [1, 256]                  65,792\n│    └─Linear: 2-12                      [1, 256]                  65,792\n├─Sequential: 1-2                        [1, 1]                    --\n│    └─Linear: 2-13                      [1, 1]                    257\n│    └─Sigmoid: 2-14                     [1, 1]                    --\n==========================================================================================\nTotal params: 671,489\nTrainable params: 671,489\nNon-trainable params: 0\nTotal mult-adds (M): 0.67\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.02\nParams size (MB): 2.69\nEstimated Total Size (MB): 2.71\n=========================================================================================="
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PredictPrice(in_features, 10, 256, \"sigmoid\")\n",
    "torchinfo.summary(model, input_size=(1, in_features))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data standardization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "features[:] = scaler.transform(features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, random_state=1, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cross validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def testing(model, x_test, y_test):\n",
    "    model.eval()\n",
    "    model = model.to(\"cpu\")\n",
    "\n",
    "    prices = []\n",
    "    for i in range(len(x_test)):\n",
    "        feature = torch.tensor((x_test.iloc[i])).float()[None, :]\n",
    "        pred_price = model(feature)\n",
    "        prices.append(pred_price.detach().item())\n",
    "\n",
    "    mae = mean_absolute_error(y_test[\"Price / Rent\"], prices)\n",
    "    mse = mean_squared_error(y_test[\"Price / Rent\"], prices)\n",
    "    r2 = r2_score(y_test[\"Price / Rent\"], prices)\n",
    "\n",
    "    return mae, mse, r2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def cross_validation(model, epoch_num, batch_size, lr, x_train, y_train, x_test, y_test):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    torch.manual_seed(13)\n",
    "\n",
    "    metrics = {\"mae\": np.inf, \"mse\": np.inf, \"r2\": -1.0}\n",
    "    best_model = None\n",
    "\n",
    "    for fold, (train_id, val_id) in enumerate(kfold.split(x_train.index)):\n",
    "        train_feature, train_label = x_train.iloc[train_id], y_train.iloc[train_id]\n",
    "        val_feature, val_label = x_train.iloc[val_id], y_train.iloc[val_id]\n",
    "        print(\"\\n\\n-------------This is fold {}----------------\".format(fold))\n",
    "\n",
    "        train_data = PriceDataset(train_feature, train_label)\n",
    "        val_data = PriceDataset(val_feature, val_label)\n",
    "        train_sampler = create_weighted_sampler(train_feature[\"Sale or Let\"].values)\n",
    "        val_sampler = create_weighted_sampler(val_feature[\"Sale or Let\"].values)\n",
    "\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False, drop_last=True, sampler=train_sampler)\n",
    "        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, drop_last=True, sampler=val_sampler)\n",
    "\n",
    "        model = model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        train_validate = TrainValidate(model, nn.MSELoss(), optimizer)\n",
    "        train_validate.set_loader(train_loader, val_loader)\n",
    "        train_validate.train(epoch_num)\n",
    "\n",
    "        mae, mse, r2 = testing(model, x_test, y_test)\n",
    "        if r2 > metrics[\"r2\"]:\n",
    "            metrics[\"r2\"] = r2\n",
    "            metrics[\"mae\"] = mae\n",
    "            metrics[\"mse\"] = mse\n",
    "            best_model = model\n",
    "\n",
    "    return best_model, metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "epoch_num = [300, 500, 1000, 3000]\n",
    "batch_size = [4, 8, 16, 32, 64, 128]\n",
    "lr = [1e-2, 3e-3, 1e-3, 3e-4, 1e-4]\n",
    "num_layers = [5, 7, 10, 13, 15]\n",
    "num_neurons = [128, 256, 512, 1024, 2048]\n",
    "activation = [\"sigmoid\", \"relu\", \"tanh\"]\n",
    "\n",
    "best_metrics = {\"epoch\": [], \"batch_size\": [], \"learning_rate\": [], \"num_layers\": [], \"num_neurons\": [], \"activation\": [],\n",
    "           \"mae\": [], \"mse\": [], \"r2\": []}\n",
    "best_models = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------This is fold 0----------------\n",
      "EPOCH: 0.376\ttrain_loss: 14353312768.000\t(4.21s - 3356.31s remaining)))"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [14]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m epoch_num:\n\u001B[1;32m      7\u001B[0m     model \u001B[38;5;241m=\u001B[39m PredictPrice(in_features, layer, neurons, activation_fn)\n\u001B[0;32m----> 9\u001B[0m     model, metrics \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m     model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m metrics[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr2\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m>\u001B[39m best_metrics[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr2\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "Input \u001B[0;32mIn [12]\u001B[0m, in \u001B[0;36mcross_validation\u001B[0;34m(model, epoch_num, batch_size, lr, x_train, y_train, x_test, y_test)\u001B[0m\n\u001B[1;32m     24\u001B[0m train_validate \u001B[38;5;241m=\u001B[39m TrainValidate(model, nn\u001B[38;5;241m.\u001B[39mMSELoss(), optimizer)\n\u001B[1;32m     25\u001B[0m train_validate\u001B[38;5;241m.\u001B[39mset_loader(train_loader, val_loader)\n\u001B[0;32m---> 26\u001B[0m \u001B[43mtrain_validate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch_num\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m mae, mse, r2 \u001B[38;5;241m=\u001B[39m testing(model, x_test, y_test)\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m r2 \u001B[38;5;241m>\u001B[39m metrics[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr2\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[0;32m~/Documents/Year 5/Individual Project/sell property/build_model/TrainValidate.py:74\u001B[0m, in \u001B[0;36mTrainValidate.train\u001B[0;34m(self, epochs, seed)\u001B[0m\n\u001B[1;32m     72\u001B[0m N \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_loader)\n\u001B[1;32m     73\u001B[0m batch_loss \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 74\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_loader):\n\u001B[1;32m     75\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_batch(data)\n\u001B[1;32m     76\u001B[0m     batch_loss\u001B[38;5;241m.\u001B[39mappend(loss)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/utils/data/dataloader.py:644\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    641\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    642\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    643\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 644\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    645\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    646\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    647\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    648\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/utils/data/dataloader.py:682\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    680\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    681\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 682\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    683\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    684\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36mPriceDataset.__getitem__\u001B[0;34m(self, item)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, item):\n\u001B[1;32m      8\u001B[0m     features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures\u001B[38;5;241m.\u001B[39mto_numpy()[item]\n\u001B[0;32m----> 9\u001B[0m     features \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels\u001B[38;5;241m.\u001B[39mto_numpy()[item]\n\u001B[1;32m     12\u001B[0m     price \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(labels[\u001B[38;5;241m1\u001B[39m])\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "layer = 5\n",
    "neurons = 128\n",
    "activation_fn = \"relu\"\n",
    "size = 16\n",
    "rate = 1e-3\n",
    "for epoch in epoch_num:\n",
    "    model = PredictPrice(in_features, layer, neurons, activation_fn)\n",
    "\n",
    "    model, metrics = cross_validation(model, epoch, size, rate, x_train, y_train, x_test, y_test)\n",
    "\n",
    "    best_metrics[\"r2\"].append(metrics[\"r2\"])\n",
    "    best_metrics[\"mae\"].append(metrics[\"mae\"])\n",
    "    best_metrics[\"mse\"].append(metrics[\"mse\"])\n",
    "    best_metrics[\"epoch\"].append(epoch)\n",
    "    best_metrics[\"batch_size\"].append(size)\n",
    "    best_metrics[\"learning_rate\"].append(rate)\n",
    "    best_metrics[\"num_layers\"].append(layer)\n",
    "    best_metrics[\"num_neurons\"].append(neurons)\n",
    "    best_metrics[\"activation\"].append(activation_fn)\n",
    "    best_models.append(model)\n",
    "\n",
    "    print(\"R2: {}\".format(metrics[\"r2\"]))\n",
    "torch.save(best_metrics, \"metrics.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}