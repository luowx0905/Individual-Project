{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "\n",
    "import torchinfo\n",
    "from torch_snippets import Report\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from TrainValidate import TrainValidate, create_weighted_sampler\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.has_mps:\n",
    "    device = \"mps\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'mps'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"../datasets/final_features_removed.csv\")\n",
    "labels = pd.read_csv(\"../datasets/final_labels_removed.csv\")\n",
    "sources = pd.read_csv(\"../datasets/final_sources_removed.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create class for collecting data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class PriceDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        assert len(features) == len(labels)\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        features = self.features.to_numpy()[item]\n",
    "        features = torch.tensor(features).float().to(device)\n",
    "\n",
    "        labels = self.labels.to_numpy()[item]\n",
    "        price = torch.tensor(labels[1]).float().to(device)\n",
    "\n",
    "        return features, price\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "temp = PriceDataset(features, labels)\n",
    "in_features = len(temp[0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class PredictPrice(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "\n",
    "        self.hidden = nn.Sequential(nn.Linear(in_features, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(128, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(128, 256),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(256, 128),\n",
    "                                    nn.ReLU())\n",
    "        self.price = nn.Sequential(nn.Linear(128, 1),\n",
    "                                   nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        price = self.price(x)\n",
    "        return price.squeeze()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nPredictPrice                             --                        --\n├─Sequential: 1-1                        [1, 128]                  --\n│    └─Linear: 2-1                       [1, 128]                  6,656\n│    └─ReLU: 2-2                         [1, 128]                  --\n│    └─Linear: 2-3                       [1, 128]                  16,512\n│    └─ReLU: 2-4                         [1, 128]                  --\n│    └─Linear: 2-5                       [1, 256]                  33,024\n│    └─ReLU: 2-6                         [1, 256]                  --\n│    └─Linear: 2-7                       [1, 128]                  32,896\n│    └─ReLU: 2-8                         [1, 128]                  --\n├─Sequential: 1-2                        [1, 1]                    --\n│    └─Linear: 2-9                       [1, 1]                    129\n│    └─ReLU: 2-10                        [1, 1]                    --\n==========================================================================================\nTotal params: 89,217\nTrainable params: 89,217\nNon-trainable params: 0\nTotal mult-adds (M): 0.09\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.01\nParams size (MB): 0.36\nEstimated Total Size (MB): 0.36\n=========================================================================================="
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PredictPrice(in_features)\n",
    "torchinfo.summary(model, input_size=(1, in_features))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data standardization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "features[:] = scaler.transform(features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model\n",
    "## Prepare data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, random_state=1, test_size=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cross validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------This is fold 0----------------\n",
      "EPOCH: 0.795\ttrain_loss: 2964534272.000\t(5.32s - 6687.62s remaining))))"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [22]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     19\u001B[0m train_validate \u001B[38;5;241m=\u001B[39m TrainValidate(model, nn\u001B[38;5;241m.\u001B[39mMSELoss(), optimizer)\n\u001B[1;32m     20\u001B[0m train_validate\u001B[38;5;241m.\u001B[39mset_loader(train_loader, val_loader)\n\u001B[0;32m---> 21\u001B[0m \u001B[43mtrain_validate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m train_validate\u001B[38;5;241m.\u001B[39msave_model(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels/all_removed_full_epoch_1000_fold_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(fold))\n",
      "File \u001B[0;32m~/Documents/Year 5/Individual Project/sell property/build_model/TrainValidate.py:69\u001B[0m, in \u001B[0;36mTrainValidate.train\u001B[0;34m(self, epochs, seed)\u001B[0m\n\u001B[1;32m     67\u001B[0m batch_loss \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_loader):\n\u001B[0;32m---> 69\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     70\u001B[0m     batch_loss\u001B[38;5;241m.\u001B[39mappend(loss)\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mrecord(epoch \u001B[38;5;241m+\u001B[39m (i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m/\u001B[39m N, train_loss\u001B[38;5;241m=\u001B[39mloss, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\r\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Year 5/Individual Project/sell property/build_model/TrainValidate.py:45\u001B[0m, in \u001B[0;36mTrainValidate.train_batch\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     44\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m---> 45\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/optim/optimizer.py:88\u001B[0m, in \u001B[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     86\u001B[0m profile_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimizer.step#\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.step\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(obj\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m     87\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(profile_name):\n\u001B[0;32m---> 88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[0;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/optim/adam.py:150\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    146\u001B[0m                 max_exp_avg_sqs\u001B[38;5;241m.\u001B[39mappend(state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_exp_avg_sq\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m    148\u001B[0m             state_steps\u001B[38;5;241m.\u001B[39mappend(state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstep\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m--> 150\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[43m         \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[43m         \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[43m         \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m         \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m         \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m         \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m         \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m         \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m         \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m         \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m         \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m         \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    163\u001B[0m \u001B[43m         \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/optim/adam.py:204\u001B[0m, in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    201\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    202\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[0;32m--> 204\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    205\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    206\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    207\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    208\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    209\u001B[0m \u001B[43m     \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    210\u001B[0m \u001B[43m     \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    211\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    212\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    213\u001B[0m \u001B[43m     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[43m     \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    215\u001B[0m \u001B[43m     \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    216\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/optim/adam.py:251\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    248\u001B[0m     grad \u001B[38;5;241m=\u001B[39m grad\u001B[38;5;241m.\u001B[39madd(param, alpha\u001B[38;5;241m=\u001B[39mweight_decay)\n\u001B[1;32m    250\u001B[0m \u001B[38;5;66;03m# Decay the first and second moment running average coefficient\u001B[39;00m\n\u001B[0;32m--> 251\u001B[0m \u001B[43mexp_avg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmul_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbeta1\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    252\u001B[0m exp_avg_sq\u001B[38;5;241m.\u001B[39mmul_(beta2)\u001B[38;5;241m.\u001B[39maddcmul_(grad, grad\u001B[38;5;241m.\u001B[39mconj(), value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m beta2)\n\u001B[1;32m    253\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m amsgrad:\n\u001B[1;32m    254\u001B[0m     \u001B[38;5;66;03m# Maintains the maximum of all 2nd moment running avg. till now\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "torch.manual_seed(13)\n",
    "in_features = len(x_train.iloc[0])\n",
    "epochs = 1000\n",
    "\n",
    "for fold, (train_id, val_id) in enumerate(kfold.split(x_train.index)):\n",
    "    train_feature, train_label = x_train.iloc[train_id], y_train.iloc[train_id]\n",
    "    val_feature, val_label = x_train.iloc[val_id], y_train.iloc[val_id]\n",
    "    print(\"\\n\\n-------------This is fold {}----------------\".format(fold))\n",
    "\n",
    "    train_data = PriceDataset(train_feature, train_label)\n",
    "    val_data = PriceDataset(val_feature, val_label)\n",
    "    train_loader = DataLoader(train_data, batch_size=16, shuffle=False, drop_last=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=16, shuffle=False, drop_last=True)\n",
    "\n",
    "    model = PredictPrice(in_features).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    train_validate = TrainValidate(model, nn.MSELoss(), optimizer)\n",
    "    train_validate.set_loader(train_loader, val_loader)\n",
    "    train_validate.train(epochs)\n",
    "\n",
    "    train_validate.save_model(\"models/all_removed_full_epoch_1000_fold_{}.pth\".format(fold))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing the performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "filename = \"models/all_removed_full_epoch_1000_fold_1.pth\"\n",
    "\n",
    "model = torch.load(filename, map_location=torch.device(\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "prices = []\n",
    "for i in range(len(x_test)):\n",
    "    feature = torch.tensor((x_test.iloc[i])).float()\n",
    "    pred_price = model(feature)\n",
    "    prices.append(pred_price.detach().item())\n",
    "\n",
    "pred = pd.DataFrame({\"PredictPrice\": prices, \"Price\": y_test[\"Price / Rent\"]})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "error = []\n",
    "for i in range(len(pred)):\n",
    "    truth = pred[\"Price\"].iloc[i]\n",
    "    predict = pred[\"PredictPrice\"].iloc[i]\n",
    "    error.append(abs(truth - predict) / truth)\n",
    "\n",
    "avg_error = sum(error) / len(error)\n",
    "error = pd.DataFrame({\"Error\": error})\n",
    "error = error.rename(index={i: j for i, j in zip(error.index, pred.index)})\n",
    "pred = pd.concat([pred, error], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "      PredictPrice     Price     Error\n3497       0.00000     525.0  1.000000\n4669  310436.25000  270000.0  0.149764\n5356  590802.37500  580000.0  0.018625\n5835       0.00000     385.0  1.000000\n8435       0.00000    1400.0  1.000000\n...            ...       ...       ...\n7173       0.00000    1300.0  1.000000\n1392  464215.90625  520000.0  0.107277\n3639  295281.09375  450000.0  0.343820\n7216       0.00000     750.0  1.000000\n7435  225982.87500  225000.0  0.004368\n\n[918 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PredictPrice</th>\n      <th>Price</th>\n      <th>Error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3497</th>\n      <td>0.00000</td>\n      <td>525.0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>4669</th>\n      <td>310436.25000</td>\n      <td>270000.0</td>\n      <td>0.149764</td>\n    </tr>\n    <tr>\n      <th>5356</th>\n      <td>590802.37500</td>\n      <td>580000.0</td>\n      <td>0.018625</td>\n    </tr>\n    <tr>\n      <th>5835</th>\n      <td>0.00000</td>\n      <td>385.0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>8435</th>\n      <td>0.00000</td>\n      <td>1400.0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7173</th>\n      <td>0.00000</td>\n      <td>1300.0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1392</th>\n      <td>464215.90625</td>\n      <td>520000.0</td>\n      <td>0.107277</td>\n    </tr>\n    <tr>\n      <th>3639</th>\n      <td>295281.09375</td>\n      <td>450000.0</td>\n      <td>0.343820</td>\n    </tr>\n    <tr>\n      <th>7216</th>\n      <td>0.00000</td>\n      <td>750.0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>7435</th>\n      <td>225982.87500</td>\n      <td>225000.0</td>\n      <td>0.004368</td>\n    </tr>\n  </tbody>\n</table>\n<p>918 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Number of sale and rental data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"../datasets/final_features.csv\")\n",
    "sale_rent = torch.tensor(features[\"Sale or Let\"].values)\n",
    "classes, count = sale_rent.unique(return_counts=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([0, 1]), tensor([2959, 6218]))"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes, count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Weighted random sampler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weight = 1.0 / count.float()\n",
    "weight"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_weights = weight[sale_rent.squeeze().long()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_weights[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sale_rent[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator = torch.Generator()\n",
    "\n",
    "sampler = WeightedRandomSampler(weights=sample_weights,\n",
    "                                num_samples=len(sample_weights),\n",
    "                                generator=generator,\n",
    "                                replacement=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data = PriceDataset(features, labels)\n",
    "train_loader = DataLoader(train_data, batch_size=2, sampler=sampler)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare data\n",
    "## Load data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"../datasets/final_features.csv\")\n",
    "labels = pd.read_csv(\"../datasets/final_labels.csv\")\n",
    "sources = pd.read_csv(\"../datasets/final_sources.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data standardization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "features[:] = scaler.transform(features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, random_state=1, test_size=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------This is fold 0----------------\n",
      "EPOCH: 0.566\ttrain_loss: 29949804544.000\t(3.78s - 6685.29s remaining))"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [26]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     23\u001B[0m train_validate \u001B[38;5;241m=\u001B[39m TrainValidate(model, nn\u001B[38;5;241m.\u001B[39mMSELoss(), optimizer)\n\u001B[1;32m     24\u001B[0m train_validate\u001B[38;5;241m.\u001B[39mset_loader(train_loader, val_loader)\n\u001B[0;32m---> 25\u001B[0m \u001B[43mtrain_validate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m train_validate\u001B[38;5;241m.\u001B[39msave_model(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels/all_removed_weighted_sampler_full_epoch_1000_fold_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(fold))\n",
      "File \u001B[0;32m~/Documents/Year 5/Individual Project/sell property/build_model/TrainValidate.py:68\u001B[0m, in \u001B[0;36mTrainValidate.train\u001B[0;34m(self, epochs, seed)\u001B[0m\n\u001B[1;32m     66\u001B[0m N \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_loader)\n\u001B[1;32m     67\u001B[0m batch_loss \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 68\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_loader):\n\u001B[1;32m     69\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_batch(data)\n\u001B[1;32m     70\u001B[0m     batch_loss\u001B[38;5;241m.\u001B[39mappend(loss)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/utils/data/dataloader.py:645\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    643\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m    644\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[0;32m--> 645\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    646\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    647\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    648\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n\u001B[1;32m    649\u001B[0m     warn_msg \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLength of IterableDataset \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m was reported to be \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m (when accessing len(dataloader)), but \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    650\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples have been fetched. \u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called,\n\u001B[1;32m    651\u001B[0m                                                       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "torch.manual_seed(13)\n",
    "in_features = len(x_train.iloc[0])\n",
    "epochs = 1000\n",
    "\n",
    "for fold, (train_id, val_id) in enumerate(kfold.split(x_train.index)):\n",
    "    train_feature, train_label = x_train.iloc[train_id], y_train.iloc[train_id]\n",
    "    val_feature, val_label = x_train.iloc[val_id], y_train.iloc[val_id]\n",
    "    print(\"\\n\\n-------------This is fold {}----------------\".format(fold))\n",
    "\n",
    "    train_data = PriceDataset(train_feature, train_label)\n",
    "    val_data = PriceDataset(val_feature, val_label)\n",
    "\n",
    "    train_sampler = create_weighted_sampler(train_feature[\"Sale or Let\"].values)\n",
    "    val_sampler = create_weighted_sampler(val_feature[\"Sale or Let\"].values)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=16, drop_last=True, sampler=train_sampler)\n",
    "    val_loader = DataLoader(val_data, batch_size=16, drop_last=True, sampler=val_sampler)\n",
    "\n",
    "    model = PredictPrice(in_features).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    train_validate = TrainValidate(model, nn.MSELoss(), optimizer)\n",
    "    train_validate.set_loader(train_loader, val_loader)\n",
    "    train_validate.train(epochs)\n",
    "\n",
    "    train_validate.save_model(\"models/all_removed_weighted_sampler_full_epoch_1000_fold_{}.pth\".format(fold))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test performance (weighted sampler)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "filename = \"models/all_removed_weighted_sampler_full_epoch_1000_fold_2.pth\"\n",
    "\n",
    "model = torch.load(filename, map_location=torch.device(\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "prices = []\n",
    "for i in range(len(x_test)):\n",
    "    feature = torch.tensor((x_test.iloc[i])).float()\n",
    "    pred_price = model(feature)\n",
    "    prices.append(pred_price.detach().item())\n",
    "\n",
    "pred = pd.DataFrame({\"PredictPrice\": prices, \"Price\": y_test[\"Price / Rent\"]})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "error = []\n",
    "for i in range(len(pred)):\n",
    "    truth = pred[\"Price\"].iloc[i]\n",
    "    predict = pred[\"PredictPrice\"].iloc[i]\n",
    "    error.append(abs(truth - predict) / truth)\n",
    "\n",
    "avg_error = sum(error) / len(error)\n",
    "error = pd.DataFrame({\"Error\": error})\n",
    "error = error.rename(index={i: j for i, j in zip(error.index, pred.index)})\n",
    "pred = pd.concat([pred, error], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "       PredictPrice     Price     Error\n3497     842.390564     525.0  0.604553\n4669  348821.093750  270000.0  0.291930\n5356  905768.000000  580000.0  0.561669\n5835     551.455383     385.0  0.432352\n8435    1037.775879    1400.0  0.258732\n...             ...       ...       ...\n7173     868.048767    1300.0  0.332270\n1392  522328.250000  520000.0  0.004477\n3639  305598.312500  450000.0  0.320893\n7216    1240.245605     750.0  0.653661\n7435  232937.843750  225000.0  0.035279\n\n[918 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PredictPrice</th>\n      <th>Price</th>\n      <th>Error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3497</th>\n      <td>842.390564</td>\n      <td>525.0</td>\n      <td>0.604553</td>\n    </tr>\n    <tr>\n      <th>4669</th>\n      <td>348821.093750</td>\n      <td>270000.0</td>\n      <td>0.291930</td>\n    </tr>\n    <tr>\n      <th>5356</th>\n      <td>905768.000000</td>\n      <td>580000.0</td>\n      <td>0.561669</td>\n    </tr>\n    <tr>\n      <th>5835</th>\n      <td>551.455383</td>\n      <td>385.0</td>\n      <td>0.432352</td>\n    </tr>\n    <tr>\n      <th>8435</th>\n      <td>1037.775879</td>\n      <td>1400.0</td>\n      <td>0.258732</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7173</th>\n      <td>868.048767</td>\n      <td>1300.0</td>\n      <td>0.332270</td>\n    </tr>\n    <tr>\n      <th>1392</th>\n      <td>522328.250000</td>\n      <td>520000.0</td>\n      <td>0.004477</td>\n    </tr>\n    <tr>\n      <th>3639</th>\n      <td>305598.312500</td>\n      <td>450000.0</td>\n      <td>0.320893</td>\n    </tr>\n    <tr>\n      <th>7216</th>\n      <td>1240.245605</td>\n      <td>750.0</td>\n      <td>0.653661</td>\n    </tr>\n    <tr>\n      <th>7435</th>\n      <td>232937.843750</td>\n      <td>225000.0</td>\n      <td>0.035279</td>\n    </tr>\n  </tbody>\n</table>\n<p>918 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Separate sale and rental data\n",
    "## Load datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"../datasets/final_features.csv\")\n",
    "labels = pd.read_csv(\"../datasets/final_labels.csv\")\n",
    "sources = pd.read_csv(\"../datasets/final_sources.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split sale and rental data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "sale_features = features[features[\"Sale or Let\"] == 1]\n",
    "sale_features = sale_features.loc[:, ~sale_features.columns.isin([\"Sale or Let\"])]\n",
    "sale_labels = labels.iloc[sale_features.index]\n",
    "\n",
    "rental_features = features[features[\"Sale or Let\"] == 0]\n",
    "rental_features = rental_features.loc[:, ~rental_features.columns.isin([\"Sale or Let\"])]\n",
    "rental_labels = labels.iloc[rental_features.index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data standardization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(sale_features)\n",
    "scaled_sale_feature = sale_features.copy()\n",
    "scaled_sale_feature[:] = scaler.fit_transform(scaled_sale_feature)\n",
    "\n",
    "scaler.fit(rental_features)\n",
    "scaled_rental_feature = rental_features.copy()\n",
    "scaled_rental_feature[:] = scaler.fit_transform(scaled_rental_feature)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split sale data into training and validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(scaled_sale_feature, sale_labels, random_state=1, test_size=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the model (sale)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------This is fold 0----------------\n",
      "EPOCH: 0.713\ttrain_loss: 18946342912.000\t(3.26s - 4574.24s remaining)))"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [32]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     19\u001B[0m train_validate \u001B[38;5;241m=\u001B[39m TrainValidate(model, nn\u001B[38;5;241m.\u001B[39mMSELoss(), optimizer)\n\u001B[1;32m     20\u001B[0m train_validate\u001B[38;5;241m.\u001B[39mset_loader(train_loader, val_loader)\n\u001B[0;32m---> 21\u001B[0m \u001B[43mtrain_validate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m train_validate\u001B[38;5;241m.\u001B[39msave_model(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels/sale_only_removed_full_epoch_1000_fold_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(fold))\n",
      "File \u001B[0;32m~/Documents/Year 5/Individual Project/sell property/build_model/TrainValidate.py:68\u001B[0m, in \u001B[0;36mTrainValidate.train\u001B[0;34m(self, epochs, seed)\u001B[0m\n\u001B[1;32m     66\u001B[0m N \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_loader)\n\u001B[1;32m     67\u001B[0m batch_loss \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 68\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_loader):\n\u001B[1;32m     69\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_batch(data)\n\u001B[1;32m     70\u001B[0m     batch_loss\u001B[38;5;241m.\u001B[39mappend(loss)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/utils/data/dataloader.py:644\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    641\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    642\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    643\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 644\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    645\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    646\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    647\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    648\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/utils/data/dataloader.py:682\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    680\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    681\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 682\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    683\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    684\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Input \u001B[0;32mIn [16]\u001B[0m, in \u001B[0;36mPriceDataset.__getitem__\u001B[0;34m(self, item)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, item):\n\u001B[1;32m      8\u001B[0m     features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures\u001B[38;5;241m.\u001B[39mto_numpy()[item]\n\u001B[0;32m----> 9\u001B[0m     features \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels\u001B[38;5;241m.\u001B[39mto_numpy()[item]\n\u001B[1;32m     12\u001B[0m     price \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(labels[\u001B[38;5;241m1\u001B[39m])\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "torch.manual_seed(13)\n",
    "in_features = len(x_train.iloc[0])\n",
    "epochs = 1000\n",
    "\n",
    "for fold, (train_id, val_id) in enumerate(kfold.split(x_train.index)):\n",
    "    train_feature, train_label = x_train.iloc[train_id], y_train.iloc[train_id]\n",
    "    val_feature, val_label = x_train.iloc[val_id], y_train.iloc[val_id]\n",
    "    print(\"\\n\\n-------------This is fold {}----------------\".format(fold))\n",
    "\n",
    "    train_data = PriceDataset(train_feature, train_label)\n",
    "    val_data = PriceDataset(val_feature, val_label)\n",
    "    train_loader = DataLoader(train_data, batch_size=16, drop_last=True, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=16, drop_last=True, shuffle=True)\n",
    "\n",
    "    model = PredictPrice(in_features).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    train_validate = TrainValidate(model, nn.MSELoss(), optimizer)\n",
    "    train_validate.set_loader(train_loader, val_loader)\n",
    "    train_validate.train(epochs)\n",
    "\n",
    "    train_validate.save_model(\"models/sale_only_removed_full_epoch_1000_fold_{}.pth\".format(fold))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test Performance (sale only)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "filename = \"models/sale_only_removed_full_epoch_1000_fold_1.pth\"\n",
    "\n",
    "model = torch.load(filename, map_location=torch.device(\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "prices = []\n",
    "for i in range(len(x_test)):\n",
    "    feature = torch.tensor((x_test.iloc[i])).float()\n",
    "    pred_price = model(feature)\n",
    "    prices.append(pred_price.detach().item())\n",
    "\n",
    "pred = pd.DataFrame({\"PredictPrice\": prices, \"Price\": y_test[\"Price / Rent\"]})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "error = []\n",
    "for i in range(len(pred)):\n",
    "    truth = pred[\"Price\"].iloc[i]\n",
    "    predict = pred[\"PredictPrice\"].iloc[i]\n",
    "    error.append(abs(truth - predict) / truth)\n",
    "\n",
    "avg_error = sum(error) / len(error)\n",
    "error = pd.DataFrame({\"Error\": error})\n",
    "error = error.rename(index={i: j for i, j in zip(error.index, pred.index)})\n",
    "pred = pd.concat([pred, error], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "       PredictPrice     Price     Error\n5071  187159.578125  300000.0  0.376135\n6456  348365.812500  350000.0  0.004669\n3547  241875.140625  200000.0  0.209376\n6245  215270.140625  220000.0  0.021499\n5482  557764.937500  460000.0  0.212532\n...             ...       ...       ...\n7894  217496.171875  210000.0  0.035696\n5417  423593.906250  235000.0  0.802527\n6981  454386.437500  450000.0  0.009748\n431   157286.703125  137000.0  0.148078\n6209  136988.062500  160000.0  0.143825\n\n[622 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PredictPrice</th>\n      <th>Price</th>\n      <th>Error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5071</th>\n      <td>187159.578125</td>\n      <td>300000.0</td>\n      <td>0.376135</td>\n    </tr>\n    <tr>\n      <th>6456</th>\n      <td>348365.812500</td>\n      <td>350000.0</td>\n      <td>0.004669</td>\n    </tr>\n    <tr>\n      <th>3547</th>\n      <td>241875.140625</td>\n      <td>200000.0</td>\n      <td>0.209376</td>\n    </tr>\n    <tr>\n      <th>6245</th>\n      <td>215270.140625</td>\n      <td>220000.0</td>\n      <td>0.021499</td>\n    </tr>\n    <tr>\n      <th>5482</th>\n      <td>557764.937500</td>\n      <td>460000.0</td>\n      <td>0.212532</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7894</th>\n      <td>217496.171875</td>\n      <td>210000.0</td>\n      <td>0.035696</td>\n    </tr>\n    <tr>\n      <th>5417</th>\n      <td>423593.906250</td>\n      <td>235000.0</td>\n      <td>0.802527</td>\n    </tr>\n    <tr>\n      <th>6981</th>\n      <td>454386.437500</td>\n      <td>450000.0</td>\n      <td>0.009748</td>\n    </tr>\n    <tr>\n      <th>431</th>\n      <td>157286.703125</td>\n      <td>137000.0</td>\n      <td>0.148078</td>\n    </tr>\n    <tr>\n      <th>6209</th>\n      <td>136988.062500</td>\n      <td>160000.0</td>\n      <td>0.143825</td>\n    </tr>\n  </tbody>\n</table>\n<p>622 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split rental data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(scaled_rental_feature, rental_labels, random_state=1, test_size=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the model (rental)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------This is fold 0----------------\n",
      "EPOCH: 1.045\ttrain_loss: 289251.406\t(2.53s - 2415.45s remaining))"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [34]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     19\u001B[0m train_validate \u001B[38;5;241m=\u001B[39m TrainValidate(model, nn\u001B[38;5;241m.\u001B[39mMSELoss(), optimizer)\n\u001B[1;32m     20\u001B[0m train_validate\u001B[38;5;241m.\u001B[39mset_loader(train_loader, val_loader)\n\u001B[0;32m---> 21\u001B[0m \u001B[43mtrain_validate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m train_validate\u001B[38;5;241m.\u001B[39msave_model(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels/rental_only_removed_full_epoch_1000_fold_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(fold))\n",
      "File \u001B[0;32m~/Documents/Year 5/Individual Project/sell property/build_model/TrainValidate.py:69\u001B[0m, in \u001B[0;36mTrainValidate.train\u001B[0;34m(self, epochs, seed)\u001B[0m\n\u001B[1;32m     67\u001B[0m batch_loss \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_loader):\n\u001B[0;32m---> 69\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     70\u001B[0m     batch_loss\u001B[38;5;241m.\u001B[39mappend(loss)\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mrecord(epoch \u001B[38;5;241m+\u001B[39m (i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m/\u001B[39m N, train_loss\u001B[38;5;241m=\u001B[39mloss, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\r\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Year 5/Individual Project/sell property/build_model/TrainValidate.py:45\u001B[0m, in \u001B[0;36mTrainValidate.train_batch\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     44\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m---> 45\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/optim/optimizer.py:88\u001B[0m, in \u001B[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     86\u001B[0m profile_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimizer.step#\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.step\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(obj\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m     87\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(profile_name):\n\u001B[0;32m---> 88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[0;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/optim/adam.py:150\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    146\u001B[0m                 max_exp_avg_sqs\u001B[38;5;241m.\u001B[39mappend(state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_exp_avg_sq\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m    148\u001B[0m             state_steps\u001B[38;5;241m.\u001B[39mappend(state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstep\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m--> 150\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[43m         \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[43m         \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[43m         \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m         \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m         \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m         \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m         \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m         \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m         \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m         \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m         \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m         \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    163\u001B[0m \u001B[43m         \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/optim/adam.py:204\u001B[0m, in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    201\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    202\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[0;32m--> 204\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    205\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    206\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    207\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    208\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    209\u001B[0m \u001B[43m     \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    210\u001B[0m \u001B[43m     \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    211\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    212\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    213\u001B[0m \u001B[43m     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[43m     \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    215\u001B[0m \u001B[43m     \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    216\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/optim/adam.py:264\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    259\u001B[0m     denom \u001B[38;5;241m=\u001B[39m (exp_avg_sq\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m math\u001B[38;5;241m.\u001B[39msqrt(bias_correction2))\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[1;32m    263\u001B[0m step_size \u001B[38;5;241m=\u001B[39m lr \u001B[38;5;241m/\u001B[39m bias_correction1\n\u001B[0;32m--> 264\u001B[0m \u001B[43mparam\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maddcdiv_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexp_avg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdenom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43mstep_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "torch.manual_seed(13)\n",
    "in_features = len(x_train.iloc[0])\n",
    "epochs = 1000\n",
    "\n",
    "for fold, (train_id, val_id) in enumerate(kfold.split(x_train.index)):\n",
    "    train_feature, train_label = x_train.iloc[train_id], y_train.iloc[train_id]\n",
    "    val_feature, val_label = x_train.iloc[val_id], y_train.iloc[val_id]\n",
    "    print(\"\\n\\n-------------This is fold {}----------------\".format(fold))\n",
    "\n",
    "    train_data = PriceDataset(train_feature, train_label)\n",
    "    val_data = PriceDataset(val_feature, val_label)\n",
    "    train_loader = DataLoader(train_data, batch_size=16, drop_last=True, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=16, drop_last=True, shuffle=True)\n",
    "\n",
    "    model = PredictPrice(in_features).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    train_validate = TrainValidate(model, nn.MSELoss(), optimizer)\n",
    "    train_validate.set_loader(train_loader, val_loader)\n",
    "    train_validate.train(epochs)\n",
    "\n",
    "    train_validate.save_model(\"models/rental_only_removed_full_epoch_1000_fold_{}.pth\".format(fold))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test performance (rental only)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "filename = \"models/rental_only_removed_full_epoch_1000_fold_2.pth\"\n",
    "\n",
    "model = torch.load(filename, map_location=torch.device(\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "prices = []\n",
    "for i in range(len(x_test)):\n",
    "    feature = torch.tensor((x_test.iloc[i])).float()\n",
    "    pred_price = model(feature)\n",
    "    prices.append(pred_price.detach().item())\n",
    "\n",
    "pred = pd.DataFrame({\"PredictPrice\": prices, \"Price\": y_test[\"Price / Rent\"]})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "error = []\n",
    "for i in range(len(pred)):\n",
    "    truth = pred[\"Price\"].iloc[i]\n",
    "    predict = pred[\"PredictPrice\"].iloc[i]\n",
    "    error.append(abs(truth - predict) / truth)\n",
    "\n",
    "avg_error = sum(error) / len(error)\n",
    "error = pd.DataFrame({\"Error\": error})\n",
    "error = error.rename(index={i: j for i, j in zip(error.index, pred.index)})\n",
    "pred = pd.concat([pred, error], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "      PredictPrice   Price     Error\n2445   1172.183594  1400.0  0.162726\n3121      0.000000     1.0  1.000000\n3556    776.037659   750.0  0.034717\n4569    733.201904   775.0  0.053933\n4838    463.209137   475.0  0.024823\n...            ...     ...       ...\n2812   1180.131714  1295.0  0.088701\n803    1105.478638   850.0  0.300563\n3567    649.455688   650.0  0.000837\n8474    793.133179   675.0  0.175012\n7498   1223.504883  1250.0  0.021196\n\n[296 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PredictPrice</th>\n      <th>Price</th>\n      <th>Error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2445</th>\n      <td>1172.183594</td>\n      <td>1400.0</td>\n      <td>0.162726</td>\n    </tr>\n    <tr>\n      <th>3121</th>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>3556</th>\n      <td>776.037659</td>\n      <td>750.0</td>\n      <td>0.034717</td>\n    </tr>\n    <tr>\n      <th>4569</th>\n      <td>733.201904</td>\n      <td>775.0</td>\n      <td>0.053933</td>\n    </tr>\n    <tr>\n      <th>4838</th>\n      <td>463.209137</td>\n      <td>475.0</td>\n      <td>0.024823</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2812</th>\n      <td>1180.131714</td>\n      <td>1295.0</td>\n      <td>0.088701</td>\n    </tr>\n    <tr>\n      <th>803</th>\n      <td>1105.478638</td>\n      <td>850.0</td>\n      <td>0.300563</td>\n    </tr>\n    <tr>\n      <th>3567</th>\n      <td>649.455688</td>\n      <td>650.0</td>\n      <td>0.000837</td>\n    </tr>\n    <tr>\n      <th>8474</th>\n      <td>793.133179</td>\n      <td>675.0</td>\n      <td>0.175012</td>\n    </tr>\n    <tr>\n      <th>7498</th>\n      <td>1223.504883</td>\n      <td>1250.0</td>\n      <td>0.021196</td>\n    </tr>\n  </tbody>\n</table>\n<p>296 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}