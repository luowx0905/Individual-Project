{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "\n",
    "import torchinfo\n",
    "from torch_snippets import Report\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from TrainValidate import TrainValidate, create_weighted_sampler\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.has_mps:\n",
    "    device = \"mps\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'mps'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"../datasets/final_features.csv\")\n",
    "labels = pd.read_csv(\"../datasets/final_labels.csv\")\n",
    "sources = pd.read_csv(\"../datasets/final_sources.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create class for collecting data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class PriceDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        assert len(features) == len(labels)\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        features = self.features.to_numpy()[item]\n",
    "        features = torch.tensor(features).float().to(device)\n",
    "\n",
    "        labels = self.labels.to_numpy()[item]\n",
    "        price = torch.tensor(labels[1]).float().to(device)\n",
    "\n",
    "        return features, price\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "temp = PriceDataset(features, labels)\n",
    "in_features = len(temp[0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class PredictPrice(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "\n",
    "        self.hidden = nn.Sequential(nn.Linear(in_features, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(128, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(128, 256),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(256, 128),\n",
    "                                    nn.ReLU())\n",
    "        self.price = nn.Sequential(nn.Linear(128, 1),\n",
    "                                   nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        price = self.price(x)\n",
    "        return price.squeeze()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nPredictPrice                             --                        --\n├─Sequential: 1-1                        [1, 128]                  --\n│    └─Linear: 2-1                       [1, 128]                  6,656\n│    └─ReLU: 2-2                         [1, 128]                  --\n│    └─Linear: 2-3                       [1, 128]                  16,512\n│    └─ReLU: 2-4                         [1, 128]                  --\n│    └─Linear: 2-5                       [1, 256]                  33,024\n│    └─ReLU: 2-6                         [1, 256]                  --\n│    └─Linear: 2-7                       [1, 128]                  32,896\n│    └─ReLU: 2-8                         [1, 128]                  --\n├─Sequential: 1-2                        [1, 1]                    --\n│    └─Linear: 2-9                       [1, 1]                    129\n│    └─ReLU: 2-10                        [1, 1]                    --\n==========================================================================================\nTotal params: 89,217\nTrainable params: 89,217\nNon-trainable params: 0\nTotal mult-adds (M): 0.09\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.01\nParams size (MB): 0.36\nEstimated Total Size (MB): 0.36\n=========================================================================================="
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PredictPrice(in_features)\n",
    "torchinfo.summary(model, input_size=(1, in_features))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data standardization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "features[:] = scaler.transform(features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model\n",
    "## Prepare data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, random_state=1, test_size=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cross validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "torch.manual_seed(13)\n",
    "in_features = len(x_train.iloc[0])\n",
    "epochs = 1000\n",
    "\n",
    "for fold, (train_id, val_id) in enumerate(kfold.split(x_train.index)):\n",
    "    train_feature, train_label = x_train.iloc[train_id], y_train.iloc[train_id]\n",
    "    val_feature, val_label = x_train.iloc[val_id], y_train.iloc[val_id]\n",
    "    print(\"\\n\\n-------------This is fold {}----------------\".format(fold))\n",
    "\n",
    "    train_data = PriceDataset(train_feature, train_label)\n",
    "    val_data = PriceDataset(val_feature, val_label)\n",
    "    train_loader = DataLoader(train_data, batch_size=16, shuffle=False, drop_last=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=16, shuffle=False, drop_last=True)\n",
    "\n",
    "    model = PredictPrice(in_features).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    train_validate = TrainValidate(model, nn.MSELoss(), optimizer)\n",
    "    train_validate.set_loader(train_loader, val_loader)\n",
    "    train_validate.train(epochs)\n",
    "\n",
    "    train_validate.save_model(\"models/all_full_epoch_1000_fold_{}.pth\".format(fold))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing the performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filename = \"models/sale_full_epoch_1000_fold_1.pth\"\n",
    "\n",
    "model = torch.load(filename, map_location=torch.device(\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "prices = []\n",
    "for i in range(len(x_test)):\n",
    "    feature = torch.tensor((x_test.iloc[i])).float()\n",
    "    pred_price = model(feature)\n",
    "    prices.append(pred_price.detach().item())\n",
    "\n",
    "pred = pd.DataFrame({\"PredictPrice\": prices, \"Price\": y_test[\"Price / Rent\"]})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "error = []\n",
    "for i in range(len(pred)):\n",
    "    truth = pred[\"Price\"].iloc[i]\n",
    "    predict = pred[\"PredictPrice\"].iloc[i]\n",
    "    error.append(abs(truth - predict) / truth)\n",
    "\n",
    "avg_error = sum(error) / len(error)\n",
    "error = pd.DataFrame({\"Error\": error})\n",
    "error = error.rename(index={i: j for i, j in zip(error.index, pred.index)})\n",
    "pred = pd.concat([pred, error], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "avg_error"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Number of sale and rental data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"../datasets/final_features.csv\")\n",
    "sale_rent = torch.tensor(features[\"Sale or Let\"].values)\n",
    "classes, count = sale_rent.unique(return_counts=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classes, count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Weighted random sampler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weight = 1.0 / count.float()\n",
    "weight"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_weights = weight[sale_rent.squeeze().long()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_weights[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sale_rent[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator = torch.Generator()\n",
    "\n",
    "sampler = WeightedRandomSampler(weights=sample_weights,\n",
    "                                num_samples=len(sample_weights),\n",
    "                                generator=generator,\n",
    "                                replacement=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data = PriceDataset(features, labels)\n",
    "train_loader = DataLoader(train_data, batch_size=2, sampler=sampler)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare data\n",
    "## Load data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"../datasets/final_features.csv\")\n",
    "labels = pd.read_csv(\"../datasets/final_labels.csv\")\n",
    "sources = pd.read_csv(\"../datasets/final_sources.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data standardization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "features[:] = scaler.transform(features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, random_state=1, test_size=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "torch.manual_seed(13)\n",
    "in_features = len(x_train.iloc[0])\n",
    "epochs = 1000\n",
    "\n",
    "for fold, (train_id, val_id) in enumerate(kfold.split(x_train.index)):\n",
    "    train_feature, train_label = x_train.iloc[train_id], y_train.iloc[train_id]\n",
    "    val_feature, val_label = x_train.iloc[val_id], y_train.iloc[val_id]\n",
    "    print(\"\\n\\n-------------This is fold {}----------------\".format(fold))\n",
    "\n",
    "    train_data = PriceDataset(train_feature, train_label)\n",
    "    val_data = PriceDataset(val_feature, val_label)\n",
    "\n",
    "    train_sampler = create_weighted_sampler(train_feature[\"Sale or Let\"].values)\n",
    "    val_sampler = create_weighted_sampler(val_feature[\"Sale or Let\"].values)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=16, drop_last=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=16, drop_last=True)\n",
    "\n",
    "    model = PredictPrice(in_features).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    train_validate = TrainValidate(model, nn.MSELoss(), optimizer)\n",
    "    train_validate.set_loader(train_loader, val_loader)\n",
    "    train_validate.train(epochs)\n",
    "\n",
    "    train_validate.save_model(\"models/all_weighted_sampler_full_epoch_1000_fold_{}.pth\".format(fold))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test performance (weighted sampler)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "filename = \"models/all_weighted_sampler_full_epoch_1000_fold_2.pth\"\n",
    "\n",
    "model = torch.load(filename, map_location=torch.device(\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "prices = []\n",
    "for i in range(len(x_test)):\n",
    "    feature = torch.tensor((x_test.iloc[i])).float()\n",
    "    pred_price = model(feature)\n",
    "    prices.append(pred_price.detach().item())\n",
    "\n",
    "pred = pd.DataFrame({\"PredictPrice\": prices, \"Price\": y_test[\"Price / Rent\"]})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "error = []\n",
    "for i in range(len(pred)):\n",
    "    truth = pred[\"Price\"].iloc[i]\n",
    "    predict = pred[\"PredictPrice\"].iloc[i]\n",
    "    error.append(abs(truth - predict) / truth)\n",
    "\n",
    "avg_error = sum(error) / len(error)\n",
    "error = pd.DataFrame({\"Error\": error})\n",
    "error = error.rename(index={i: j for i, j in zip(error.index, pred.index)})\n",
    "pred = pd.concat([pred, error], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "      PredictPrice     Price          Error\n3497    45845660.0     525.0   87324.066667\n4669   186160224.0  270000.0     688.482311\n5356   197736848.0  580000.0     339.925600\n5835   164422848.0     385.0  427071.332468\n8435   150515456.0    1400.0  107510.040000\n...            ...       ...            ...\n7173    52173632.0    1300.0   40132.563077\n1392   136921328.0  520000.0     262.310246\n3639   150710944.0  450000.0     333.913209\n7216    60319196.0     750.0   80424.594667\n7435   181560576.0  225000.0     805.935893\n\n[918 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PredictPrice</th>\n      <th>Price</th>\n      <th>Error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3497</th>\n      <td>45845660.0</td>\n      <td>525.0</td>\n      <td>87324.066667</td>\n    </tr>\n    <tr>\n      <th>4669</th>\n      <td>186160224.0</td>\n      <td>270000.0</td>\n      <td>688.482311</td>\n    </tr>\n    <tr>\n      <th>5356</th>\n      <td>197736848.0</td>\n      <td>580000.0</td>\n      <td>339.925600</td>\n    </tr>\n    <tr>\n      <th>5835</th>\n      <td>164422848.0</td>\n      <td>385.0</td>\n      <td>427071.332468</td>\n    </tr>\n    <tr>\n      <th>8435</th>\n      <td>150515456.0</td>\n      <td>1400.0</td>\n      <td>107510.040000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7173</th>\n      <td>52173632.0</td>\n      <td>1300.0</td>\n      <td>40132.563077</td>\n    </tr>\n    <tr>\n      <th>1392</th>\n      <td>136921328.0</td>\n      <td>520000.0</td>\n      <td>262.310246</td>\n    </tr>\n    <tr>\n      <th>3639</th>\n      <td>150710944.0</td>\n      <td>450000.0</td>\n      <td>333.913209</td>\n    </tr>\n    <tr>\n      <th>7216</th>\n      <td>60319196.0</td>\n      <td>750.0</td>\n      <td>80424.594667</td>\n    </tr>\n    <tr>\n      <th>7435</th>\n      <td>181560576.0</td>\n      <td>225000.0</td>\n      <td>805.935893</td>\n    </tr>\n  </tbody>\n</table>\n<p>918 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Separate sale and rental data\n",
    "## Loda datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"../datasets/final_features.csv\")\n",
    "labels = pd.read_csv(\"../datasets/final_labels.csv\")\n",
    "sources = pd.read_csv(\"../datasets/final_sources.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split sale and rental data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "sale_features = features[features[\"Sale or Let\"] == 1]\n",
    "sale_features = sale_features.loc[:, ~sale_features.columns.isin([\"Sale or Let\"])]\n",
    "sale_labels = labels.iloc[sale_features.index]\n",
    "\n",
    "rental_features = features[features[\"Sale or Let\"] == 0]\n",
    "rental_features = rental_features.loc[:, ~rental_features.columns.isin([\"Sale or Let\"])]\n",
    "rental_labels = labels.iloc[rental_features.index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data standardization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(sale_features)\n",
    "scaled_sale_feature = sale_features.copy()\n",
    "scaled_sale_feature[:] = scaler.fit_transform(scaled_sale_feature)\n",
    "\n",
    "scaler.fit(rental_features)\n",
    "scaled_rental_feature = rental_features.copy()\n",
    "scaled_rental_feature[:] = scaler.fit_transform(scaled_rental_feature)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split sale data into training and validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(scaled_sale_feature, sale_labels, random_state=1, test_size=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------This is fold 0----------------\n",
      "EPOCH: 3.946\ttrain_loss: 3095473920.000\t(18.15s - 4580.12s remaining)))"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [21]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     23\u001B[0m train_validate \u001B[38;5;241m=\u001B[39m TrainValidate(model, nn\u001B[38;5;241m.\u001B[39mMSELoss(), optimizer)\n\u001B[1;32m     24\u001B[0m train_validate\u001B[38;5;241m.\u001B[39mset_loader(train_loader, val_loader)\n\u001B[0;32m---> 25\u001B[0m \u001B[43mtrain_validate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m train_validate\u001B[38;5;241m.\u001B[39msave_model(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels/sale_full_epoch_1000_fold_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(fold))\n",
      "File \u001B[0;32m~/Documents/Year 5/Individual Project/sell property/build_model/TrainValidate.py:69\u001B[0m, in \u001B[0;36mTrainValidate.train\u001B[0;34m(self, epochs, seed)\u001B[0m\n\u001B[1;32m     67\u001B[0m batch_loss \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_loader):\n\u001B[0;32m---> 69\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     70\u001B[0m     batch_loss\u001B[38;5;241m.\u001B[39mappend(loss)\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mrecord(epoch \u001B[38;5;241m+\u001B[39m (i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m/\u001B[39m N, train_loss\u001B[38;5;241m=\u001B[39mloss, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\r\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Year 5/Individual Project/sell property/build_model/TrainValidate.py:44\u001B[0m, in \u001B[0;36mTrainValidate.train_batch\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     42\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_fn(yhat, y)\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 44\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/_tensor.py:400\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    391\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    392\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    393\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    394\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    398\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[1;32m    399\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[0;32m--> 400\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ML_m1/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    170\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "torch.manual_seed(13)\n",
    "in_features = len(x_train.iloc[0])\n",
    "epochs = 1000\n",
    "\n",
    "for fold, (train_id, val_id) in enumerate(kfold.split(x_train.index)):\n",
    "    train_feature, train_label = x_train.iloc[train_id], y_train.iloc[train_id]\n",
    "    val_feature, val_label = x_train.iloc[val_id], y_train.iloc[val_id]\n",
    "    print(\"\\n\\n-------------This is fold {}----------------\".format(fold))\n",
    "\n",
    "    train_data = PriceDataset(train_feature, train_label)\n",
    "    val_data = PriceDataset(val_feature, val_label)\n",
    "\n",
    "    train_sampler = create_weighted_sampler(train_feature[\"Sale or Let\"].values)\n",
    "    val_sampler = create_weighted_sampler(val_feature[\"Sale or Let\"].values)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=16, drop_last=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=16, drop_last=True)\n",
    "\n",
    "    model = PredictPrice(in_features).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    train_validate = TrainValidate(model, nn.MSELoss(), optimizer)\n",
    "    train_validate.set_loader(train_loader, val_loader)\n",
    "    train_validate.train(epochs)\n",
    "\n",
    "    train_validate.save_model(\"models/sale_full_epoch_1000_fold_{}.pth\".format(fold))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}